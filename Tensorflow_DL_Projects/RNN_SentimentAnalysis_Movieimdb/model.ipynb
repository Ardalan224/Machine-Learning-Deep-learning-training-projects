{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-8tLa_uJaAT",
        "outputId": "2aa0061d-b4b4-424b-9c9e-0694e4c82350"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 2.x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import imdb\n",
        "from keras.preprocessing import sequence\n",
        "import numpy as np\n",
        "import os\n",
        "import keras\n",
        "import tensorflow as tf\n"
      ],
      "metadata": {
        "id": "FR1myM3nKKvw"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = 88584\n",
        "# considering 250 Words as max length of each text input\n",
        "MAXLEN = 250\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words = VOCAB_SIZE)"
      ],
      "metadata": {
        "id": "aIixanCnKrrA"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets look at one review (each word for now is represented with an Integer number)\n",
        "train_data[1]"
      ],
      "metadata": {
        "id": "-SnPjL-MK5rw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing\n",
        "\n",
        "If we have a look at some of our loaded in reviews, we'll notice that they are different lengths. This is an issue. We cannot pass different length data into our neural network. Therefore, we must make each review the same length. To do this we will follow the procedure below:\n",
        "\n",
        "if the review is greater than 250 words then trim off the extra words\n",
        "if the review is less than 250 words add the necessary amount of 0's to make it equal to 250."
      ],
      "metadata": {
        "id": "x-dOBkciOdq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = sequence.pad_sequences(train_data, MAXLEN)\n",
        "test_data = sequence.pad_sequences(test_data, MAXLEN)"
      ],
      "metadata": {
        "id": "DBIEYMf3LLdI"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining the Model\n",
        "\n",
        "We'll use a word embedding layer as the first layer in our model and add a LSTM layer afterwards that feeds into a dense node to get our predicted sentiment.\n",
        "\n",
        "32 stands for the output dimension of the vectors generated by the embedding layer. We can change this value if we'd like!"
      ],
      "metadata": {
        "id": "Tp2WLD6eOvOQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, 32),\n",
        "    tf.keras.layers.LSTM(32),\n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])"
      ],
      "metadata": {
        "id": "6ny-l4bTOtGH"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "pMzC6H2EPuRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compile and Training the model"
      ],
      "metadata": {
        "id": "eATOvr_rQXNv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"binary_crossentropy\",optimizer=\"rmsprop\",metrics=['acc'])\n",
        "\n",
        "history = model.fit(train_data, train_labels, epochs=10, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bq7VwogFQZFv",
        "outputId": "c3db25b2-62a0-4761-9203-0c4936451c7b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 68ms/step - acc: 0.6650 - loss: 0.5857 - val_acc: 0.8618 - val_loss: 0.3332\n",
            "Epoch 2/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 61ms/step - acc: 0.8814 - loss: 0.3010 - val_acc: 0.8752 - val_loss: 0.3050\n",
            "Epoch 3/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 60ms/step - acc: 0.9160 - loss: 0.2252 - val_acc: 0.8856 - val_loss: 0.2849\n",
            "Epoch 4/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 60ms/step - acc: 0.9379 - loss: 0.1771 - val_acc: 0.8606 - val_loss: 0.3578\n",
            "Epoch 5/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 60ms/step - acc: 0.9431 - loss: 0.1601 - val_acc: 0.8742 - val_loss: 0.3054\n",
            "Epoch 6/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - acc: 0.9528 - loss: 0.1356 - val_acc: 0.8870 - val_loss: 0.3231\n",
            "Epoch 7/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 59ms/step - acc: 0.9616 - loss: 0.1158 - val_acc: 0.8790 - val_loss: 0.3226\n",
            "Epoch 8/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 61ms/step - acc: 0.9674 - loss: 0.1010 - val_acc: 0.8890 - val_loss: 0.3586\n",
            "Epoch 9/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 61ms/step - acc: 0.9736 - loss: 0.0854 - val_acc: 0.8812 - val_loss: 0.3986\n",
            "Epoch 10/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 61ms/step - acc: 0.9778 - loss: 0.0718 - val_acc: 0.8744 - val_loss: 0.3726\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating the model"
      ],
      "metadata": {
        "id": "bfc6sgvQSKww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.evaluate(test_data, test_labels)\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQ62uqURSMMg",
        "outputId": "b0d5d78e-aeec-4ea2-aee5-22799ca45e92"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - acc: 0.8596 - loss: 0.4281\n",
            "[0.42475664615631104, 0.8594800233840942]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predictions\n",
        "\n",
        "Since our reviews are encoded well need to convert any custom review that we write into that form so the network can understand it. To do that well load the encodings from the dataset and use them to encode our own data."
      ],
      "metadata": {
        "id": "AwTXse1wSU5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "\n"
      ],
      "metadata": {
        "id": "aMewcJYqU40W"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_index = imdb.get_word_index()\n",
        "# Since out imdb database that the model is trained on that, had its own unique word to integer mapping\n",
        "# basically a dictionary that represents each word by a unique integer ID (its happening before the Word Embedding layer)\n",
        "def encode_text(text):\n",
        "    tokens = text_to_word_sequence(text)\n",
        "    tokens = [word_index[word] if word in word_index else 0 for word in tokens]\n",
        "    return sequence.pad_sequences([tokens], MAXLEN)[0]\n",
        "\n",
        "text = \"I actually did not like the movie at all!\"\n",
        "encoded = encode_text(text)\n",
        "print(encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hnFqpIeSlSS",
        "outputId": "cca78d72-e7cc-4c0b-e8dd-03b31aec9fbc"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0  10 162 119  21  37   1  17  30  29]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The decoding function, not necessary and useful for our case, just in order to show how\n",
        "#it converts back the integer ID vector of sentence back into the actual sentence\n",
        "\n",
        "reverse_word_index = {value: key for (key, value) in word_index.items()}\n",
        "\n",
        "def decode_integers(integers):\n",
        "    PAD = 0\n",
        "    text = \"\"\n",
        "    for num in integers:\n",
        "      if num != PAD:\n",
        "        text += reverse_word_index[num] + \" \"\n",
        "\n",
        "    return text[:-1]\n",
        "\n",
        "print(decode_integers(encoded))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuuSqJqyVSUv",
        "outputId": "ecf9e274-9205-47b2-e671-47e5ed7a54f5"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i actually did not like the movie at all\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now time to make a prediction\n",
        "\n",
        "def predict(text):\n",
        "  encoded_text = encode_text(text)\n",
        "  pred = np.zeros((1,250))\n",
        "  pred[0] = encoded_text\n",
        "  result = model.predict(pred)\n",
        "  print(result[0])\n",
        "  return (result[0])\n",
        "\n",
        "\n",
        "def translate_probabilty(probability):\n",
        "  if probability > 0.5:\n",
        "    print(\"Positive\")\n",
        "  else:\n",
        "    print(\"Negative\")\n",
        "\n",
        "positive_review = \"I really loved the movie!\"\n",
        "translate_probabilty(predict(positive_review)[0])\n",
        "\n",
        "negative_review = \"The movie was awful! I did not enjoy it\"\n",
        "translate_probabilty(predict(negative_review)[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxy4aGO9WAH1",
        "outputId": "2ba95deb-7e55-43ae-c35a-4348192b7e1a"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "[0.7449718]\n",
            "Positive\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "[0.3990567]\n",
            "Negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Source:\n",
        "\n",
        "FreeCodeCamp TensorFlow tutorial:\n",
        "https://www.freecodecamp.org/learn/machine-learning-with-python/tensorflow/natural-language-processing-with-rnns-making-predictions"
      ],
      "metadata": {
        "id": "nlhgbi85lXYt"
      }
    }
  ]
}